#!/usr/bin/env python3

from jarvis_cd.basic.jarvis_manager import JarvisManager
from jarvis_util import *
from jarvis_util.shell.slurm_exec import SlurmExec, SlurmExecInfo, SlurmHostfile
from jarvis_util.shell.pbs_exec import PbsExec, PbsExecInfo
from jarvis_cd.basic.pkg import Pipeline, PkgArgParse, PipelineIndex
from pathlib import Path
import os
import socket


class JarvisArgs(ArgParse):
    def define_options(self):
        self.jarvis = JarvisManager.get_instance()
        self.jutil = JutilManager.get_instance()
        self.define_init_opts()
        self.define_pipeline_pkg_opts()
        self.define_pipeline_index_opts()
        self.define_pipeline_opts()
        self.define_repo_opts()
        self.define_env_opts()
        self.jutil.debug_mpi_exec = False

    def define_init_opts(self):
        # jarvis
        self.add_menu(msg='A tool for configuring and deploying '
                          'complex workflows')

        # jarvis init
        self.add_cmd('init',
                      msg='Initialize jarvis cd configuration')
        self.add_args([
            {
                'name': 'CONFIG_DIR',
                'msg': 'A directory where jarvis metadata for pkgs and '
                       'pipelines are stored. This directory can be anywhere '
                       'that the current user can access.',
                'required': True,
                'pos': True
            },
            {
                'name': 'PRIVATE_DIR',
                'msg': 'A directory which is common across all machines, but '
                       'stores data locally to the machine',
                'required': True,
                'pos': True
            },
            {
                'name': 'SHARED_DIR',
                'msg': 'A directory which is common across all machines, '
                       'where each machine has the same view of data '
                       'in the directory',
                'default': None,
                'pos': True
            }
        ])
        
        # jarvis reset
        self.add_cmd('reset',
                      msg='Clean all pipelines and configurations')

        # jarvis config print
        self.add_cmd('config print',
                      msg='Print jarvis directories')

        # jarvis bootstrap
        self.add_menu('bootstrap',
                      msg='Bootstrap jarvis from a particular machine')

        # jarvis bootstrap from
        self.add_cmd('bootstrap from',
                      msg='Initialize jarvis from an existing machine')
        self.add_args([
            {
                'name': 'MACHINE',
                'msg': 'The machine to bootstrap from',
                'required': True,
                'pos': True
            }
        ])

        # jarvis bootstrap list
        self.add_cmd('bootstrap list',
                      msg='List all machines')

        # jarvis hostfile set
        self.add_cmd('hostfile set',
                      msg='Define the hostfile for the job')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The path to the hostfile of this job',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis config
        self.add_menu('config',
                      msg='View or print configure file',
                      aliases=['conf'])

        # jarvis config print
        self.add_cmd('config print',
                     msg='Print the configuration file')

        # jarvis config path
        self.add_cmd('config path',
                     msg='Print the configuration file path')

        # jarvis resource-graph
        self.add_menu('resource-graph',
                      msg='Resources to build a resource graph for a machine',
                      aliases=['rg'])

        # jarvis resource-graph show
        self.add_cmd('resource-graph show',
                     msg='Show the resource graph')

        # jarvis resource-graph show
        self.add_cmd('resource-graph path',
                     msg='Get the path to the resource graph')

        # jarvis resource-graph build
        self.add_cmd('resource-graph build',
                      msg='Introspect resource graph for this machine')
        self.add_args([
            {
                'name': 'net_sleep',
                'msg': 'How long to sleep in network tests',
                'type': float,
                'default': 5,
                'pos': False,
                'required': False
            },
            *SlurmExecInfo.get_args(),
            *PbsExecInfo.get_args()
        ])

        # jarvis resource-graph modify
        self.add_cmd('resource-graph modify',
                      msg='Modify the resource graph to introspect new resources')
        self.add_args([
            {
                'name': 'net_sleep',
                'msg': 'How long to sleep in network tests',
                'type': float,
                'default': 5,
                'pos': False,
                'required': False
            },
        ])
        
        # jarvis resource-graph add storage
        self.add_cmd('resource-graph add storage',
                      msg='Add a storage device or PFS to track')
        self.add_args([
            {
                'name': 'hostfile',
                'msg': 'The path to the hosts having the storage'
            },
            {
                'name': 'hosts',
                'msg': 'A hostfile string (e.g., ares-comp-[10-30])'
            },
            {
                'name': 'device',
                'msg': 'Device path (e.g., /dev/sda)'
            },
            {
                'name': 'mount',
                'msg': 'Where device is currently mounted'
            },
            {
                'name': 'tran',
                'msg': 'Whether the device is rotational',
                'choices': ['sata', 'nvme', 'dimm']
            },
            {
                'name': 'size',
                'msg': 'The size of the device (e.g., 16g, 32m ...)'
            },
            {
                'name': 'shared',
                'msg': 'Whether the mount is a pfs or not'
            },
        ])

        # jarvis resource-graph add net
        self.add_cmd('resource-graph add net',
                      msg='Add a network to track')
        self.add_args([
            {
                'name': 'hostfile',
                'msg': 'The path to the hosts to add'
            },
            {
                'name': 'hosts',
                'msg': 'The networks to add as a hostfile string'
            },
            {
                'name': 'provider',
                'msg': 'Network protocol (e.g., tcp, sockets, ib)'
            },
            {
                'name': 'speed',
                'msg': 'Interconnect speed'
            },
        ])

        # jarvis resource-graph filter fs
        self.add_cmd('resource-graph filter fs',
                      msg='Consider only mounts matching query')
        self.add_args([
            {
                'name': 'mount_re',
                'msg': 'A regex to match mountpoints',
                'required': True,
                'pos': True,
            },
            {
                'name': 'mount_suffix',
                'msg': 'Append a suffix to the mount point',
                'default': None
            },
        ])

        # jarvis resource-graph filter net
        self.add_cmd('resource-graph filter net',
                      msg='Consider only mounts matching query')
        self.add_args([
            {
                'name': 'hostfile',
                'msg': 'Path to hostfile for networks to filter for',
            },
            {
                'name': 'hosts',
                'msg': 'Hostfile text for networks to filter for',
            },
            {
                'name': 'ip_re',
                'msg': 'A regex of IP addresess to filter for',
            },
            {
                'name': 'speed',
                'msg': 'Indicate speed of this network subset',
            },
        ])

    def define_repo_opts(self):
        # jarvis repo
        self.add_menu('repo',
                      msg='Tools to manage the Jarvis repos')

        # jarvis repo add
        self.add_cmd('repo add',
                      msg='Register a jarvis repo')
        self.add_args([
            {
                'name': 'repo_path',
                'msg': 'The path to the repo in the filesystem',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'force',
                'msg': 'Force the repo to be added',
                'required': False,
                'pos': False,
                'default': False
            }
        ])

        # jarvis repo create
        self.add_cmd('repo create',
                      msg='Create a pkg in the primary repo')
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The name of the pkg to create',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_cls',
                'msg': 'The type of pkg to create',
                'required': True,
                'pos': True,
                'default': None,
                'choices': ['service', 'app', 'interceptor']
            },
        ])

        # jarvis repo promote
        self.add_cmd('repo promote',
                      msg='Make a repo the primary repo for '
                          'subsequent repo create commands')
        self.add_args([
            {
                'name': 'repo_name',
                'msg': 'The name of the repo to promote',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis repo remove
        self.add_cmd('repo remove',
                      msg='Remove a repo from consideration')
        self.add_args([
            {
                'name': 'repo_name',
                'msg': 'The name of the repo to remove',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis repo list
        self.add_cmd('repo list',
                      msg='List the set of repos, or list the set of pkgs')
        self.add_args([
            {
                'name': 'repo_name',
                'msg': '',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

    def define_pipeline_pkg_opts(self):
        # jarvis pkg
        self.add_menu('pkg',
                      msg='Tools to edit pkgs in a pipeline')

        # jarvis pkg help
        self.add_cmd('pkg help',
                      msg='View the help menu for a package')
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pkg configure
        self.add_cmd('pkg configure',
                      msg="Configure a pkg in the pipeline",
                      keep_remainder=True,
                      aliases=['pkg config', 'pkg conf'])
        self.add_args([
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline.',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # jarvis pkg unlink
        self.add_cmd('pkg unlink', msg="Unlink a pkg from the pipeline.")
        self.add_args([
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline.',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pkg remove
        self.add_cmd('pkg remove', msg="Remove a pkg from the pipeline.")
        self.add_args([
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg removed',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pkg src
        self.add_cmd('pkg src', msg="Print the path to the pkg.py file.")
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of the pkg being displayed',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pkg root
        self.add_cmd('pkg root', msg="Print the path to the pkg directory.")
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of the pkg being displayed',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

    def define_pipeline_index_opts(self):
        # jarvis pipeline index 
        self.add_menu('pipeline index', 
                      msg='Stored pipeline files')
        
        # jarvis pipeline index show
        self.add_cmd('pipeline index show',
                      msg='Show pipeline indexes')
        self.add_args([
            {
                'name': 'index_query',
                'msg': 'List index files or subdirectories',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarivs pipeline index copy 
        self.add_cmd('pipeline index copy',
                      msg='Show pipeline indexes')
        self.add_args([
            {
                'name': 'index_query',
                'msg': 'List index files or subdirectories',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'output_dir',
                'msg': 'List index files or subdirectories',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarivs pipeline index load 
        self.add_cmd('pipeline index load',
                      msg='Show pipeline indexes')
        self.add_args([
            {
                'name': 'index_query',
                'msg': 'List index files or subdirectories',
                'required': True,
                'pos': True,
                'default': None
            }
        ])

    def define_pipeline_opts(self):
        # jarvis cd
        self.add_cmd('cd',
                      msg='Make all jarvis operations apply to a '
                          'certain pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The unique name of the pipeline to switch to',
                'required': True,
                'pos': True,
                'default': None
            },
        ])
        self.add_cmd('getcwd',
                      msg='Get currently focused pipeline')

        # jarvis path
        self.add_cmd('path',
                      msg='Get the path of a jarvis pipeline or pkg')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The name of the pipeline to get config path for',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The name of the pkg to get the path for',
                'default': None,
                'pos': True,
                'required': False,
                'default': None
            },
            {
                'name': 'config',
                'msg': 'Get the config directory path',
                'required': False,
                'type': bool,
                'pos': False,
                'default': True
            },
            {
                'name': 'shared',
                'msg': 'Get the shared directory path',
                'required': False,
                'type': bool,
                'pos': False,
                'default': False
            },
            {
                'name': 'private',
                'msg': 'Get the private directory path',
                'required': False,
                'type': bool,
                'pos': False,
                'default': False
            },
        ])

        # jarvis pipeline
        self.add_menu('pipeline',
                      msg='Tools to create + edit a pipeline',
                      aliases=['ppl'])

        # jarvis pipeline list
        self.add_cmd('pipeline list',
                      msg='List all created pipelines')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The pipeline to list. Default None to list the'
                       'set of pipelines',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline create
        self.add_cmd('pipeline create',
                      msg='Create a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'A unique name for this pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline load yaml
        self.add_cmd('pipeline load yaml',
                      msg='Create a pipeline from a yaml schema')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The pipeline schema file path',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Whether to configure the pipeline immediately',
                'required': False,
                'pos': False,
                'default': True
            },
        ])

        # jarvis pipeline update
        self.add_cmd('pipeline update yaml', msg='Reload yaml file from its source')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'Delete the jarvis directories containing metadata'
                       'for the pipeline. Will apply to current pipeline by'
                       'default.',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline run yaml
        self.add_cmd('pipeline run yaml',
                      msg='Create a pipeline from a yaml schema')
        self.add_args([
            {
                'name': 'path',
                'msg': 'The pipeline schema file path',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline print
        self.add_cmd('pipeline print', msg="List all pkgs in a pipeline.")
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'The pipeline to list. Default None to list the'
                       'set of pipelines',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline reset
        self.add_cmd('pipeline reset', msg='Clear a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'Delete the jarvis directories containing metadata'
                       'for the pipeline. Will apply to current pipeline by'
                       'default.',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline destroy
        self.add_cmd('pipeline destroy', msg='Delete a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'Delete the jarvis directories containing metadata'
                       'for the pipeline. Will apply to current pipeline by'
                       'default.',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline update
        self.add_cmd('pipeline update', msg='Re-run configure on all pkgs '
                                             'in a pipeline')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'Delete the jarvis directories containing metadata'
                       'for the pipeline. Will apply to current pipeline by'
                       'default.',
                'required': False,
                'pos': True,
                'default': None
            },
        ])


        # jarvis pipeline append
        self.add_cmd('pipeline append',
                      msg='Append a pkg to a pipeline',
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline. By default, will be equal to '
                       'pkg_type',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # jarvis pipeline prepend
        self.add_cmd('pipeline prepend',
                      msg='Prepend a pkg to a pipeline',
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline. By default, will be equal to '
                       'pkg_type',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # jarvis pipeline insert
        self.add_cmd('pipeline insert',
                      msg='Insert a pkg to a pipeline',
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'at_id',
                'msg': 'The id of the packge to insert at',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_type',
                'msg': 'The type of pkg being added to the pipeline',
                'required': True,
                'pos': True,
                'default': None
            },
            {
                'name': 'pkg_id',
                'msg': 'The unique name of the pkg being added to '
                       'the pipeline. By default, will be equal to '
                       'pkg_type',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'conf',
                'msg': 'Should be run the configure step on the pkg',
                'required': False,
                'pos': False,
                'default': True,
                'type': bool
            },
        ])

        # pipeline env build
        self.add_cmd('pipeline env build',
                      msg="Cache relevant environment vars. Use +ENV_VAR and"
                          "-ENV_VAR in remainder list to indicate whether "
                          "to track certain variables.",
                      keep_remainder=True,
                      remainder_as_kv=True)

        # jarvis pipeline env scan
        self.add_cmd('pipeline env scan',
                      msg="Reload environment vars. Use +ENV_VAR to indicate"
                          "which variables to track.",
                      keep_remainder=True,
                      remainder_as_kv=True)

        # jarvis pipeline env track
        self.add_cmd('pipeline env track',
                      msg="Add or remove environment vars. Use +ENV_VAR and"
                          "-ENV_VAR in remainder list to indicate whether "
                          "to track certain variables.",
                      keep_remainder=True)

        # jarvis pipeline env path
        self.add_cmd('pipeline env path',
                      msg='Get the path to the pipeline env file')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'A unique name for this pipeline',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline env show
        self.add_cmd('pipeline env show',
                      msg='View the jarvis env file')
        self.add_args([
            {
                'name': 'pipeline_id',
                'msg': 'A unique name for this pipeline',
                'required': False,
                'pos': True,
                'default': None
            },
        ])

        # jarvis pipeline [run/start/stop/clean/status]
        self.add_cmd('pipeline run',
                      msg="Run + terminate a pipeline",
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'pipeline_name',
                'msg': 'The pipeline name to be run',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'script',
                'msg': 'The pipeline script to run',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'host_suffix',
                'msg': 'A suffix to append to hostfile',
                'required': False,
                'pos': False,
                'default': None,
                'type': str
            },
            {
                'name': 'resume',
                'msg': 'Resume an iterative pipeline',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
            *SlurmExecInfo.get_args(),
            *PbsExecInfo.get_args()
        ])

        self.add_cmd('pipeline start',
                      msg="Start a pipeline",
                      keep_remainder=True)
        self.add_cmd('pipeline stop',
                      msg="Stop a pipeline",
                      keep_remainder=True)
        self.add_cmd('pipeline kill',
                      msg="Kill a pipeline",
                      keep_remainder=True)
        self.add_cmd('pipeline clean',
                      msg="Clean a pipeline",
                      keep_remainder=True)
        self.add_cmd('pipeline status',
                      msg="Get the status of a pipeline",
                      keep_remainder=True)
        self.add_cmd('pipeline load',
                      msg="Load a pipeline from a file",
                      keep_remainder=True)
        self.add_args([
            {
                'name': 'path',
                'msg': 'Path to the file or folder to load the pipeline',
                'required': True,
                'pos': True,
                'default': None
            }
        ])
        self.add_cmd('pipeline save',
                      msg="Save the current pipeline",
                      keep_remainder=True)

        # jarvis pipeline sbatch
        self.add_cmd('pipeline sbatch', msg="Run the current pipeline through sbatch")
        self.add_args([
            {
                'name': 'pipeline_name',
                'msg': 'The pipeline to run',
                'required': False,
                'pos': True,
                'default': None
            },
            {
                'name': 'job_name',
                'msg': 'The name given to this job',
                'required': True,
                'pos': False,
                'default': None
            },
            {
                'name': 'nnodes',
                'msg': 'The number of nodes to execute the pipeline on',
                'required': True,
                'pos': False,
                'default': None
            },
            {
                'name': 'ppn',
                'msg': 'The number of processes per node',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'cpus_per_task',
                'msg': 'Advise the Slurm controller that ensuing job will require ncpus number of processors per task',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'time',
                'msg': 'Maximum time aloted to the job',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'partition',
                'msg': 'The partition in which to allocate the nodes',
                'required': False,
                'pos': False,
                'default': 'compute'
            },
            {
                'name': 'mail_type',
                'msg': 'When to email users of the status of the job',
                'required': False,
                'pos': False,
                'default': None,
                'choices': ['NONE', 'BEGIN', 'END', 'FAIL', 'REQUEUE', 'ALL']
            },
            {
                'name': 'mail_user',
                'msg': 'What email to use',
                'required': False,
                'pos': False,
                'default': None,
            },
            {
                'name': 'output_file',
                'msg': 'File to write all output messages',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'error_file',
                'msg': 'File to write all error messages',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'memory',
                'msg': 'Amount of memory to request for the job',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'gres',
                'msg': 'A comma-delimited list of generic consumable resources, like gpus',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'exclusive',
                'msg': 'Request the nodes exclusively',
                'required': False,
                'pos': False,
                'default': True
            },
            {
                'name': 'host_suffix',
                'msg': 'Append suffix to all hosts in hostfile',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'nodelist',
                'msg': 'A list of nodes to run the job on, exp: ares-comp-[10-14],ares-comp-15',
                'required': False,
                'pos': False,
                'type': str,
                'default': None
            }
        ])

        self.add_cmd('pipeline pbs', msg="Run the current pipeline through pbs")
        self.add_args([
            {
                'name': 'nnodes',
                'msg': 'The number of nodes to execute the pipeline on',
                'required': True,
                'pos': False,
                'default': 1
            },
            {
                'name': 'system',
                'msg': 'The type of system to allocate the nodes on',
                'required': False,
                'pos': False,
                'default': 'polaris'
            },
            {
                'name': 'filesystems',
                'msg': 'The filesystem to be used (e.g. home:grand)',
                'required': False,
                'pos': False,
                'default': 'home:grand'
            },
            {
                'name': 'walltime',
                'msg': 'Maximum time allotted to the job',
                'required': False,
                'pos': False,
                'default': '00:10:00'
            },
            {
                'name': 'account',
                'msg': 'Account used for job submission',
                'required': False,
                'pos': False,
                'default': 'VeloC'
            },
            {
                'name': 'queue',
                'msg': 'Queue in which to submit the job',
                'required': False,
                'pos': False,
                'default': 'debug-scaling'
            },
            {
                'name': 'interactive',
                'msg': 'Submit the job in interactive mode',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
            {
                'name': 'env_vars',
                'msg': 'Environmental variables to pass through PBS. '
                       'Comma separated list of strings of the form variable or variable=value',
                'required': False,
                'pos': False,
                'default': None
            },
            {
                'name': 'polaris',
                'msg': 'Submit using polaris',
                'required': False,
                'pos': False,
                'default': False,
                'type': bool
            },
        ])

        # sched
        self.add_menu('sched')

        # sched hostfile build
        self.add_cmd('sched hostfile build')
        self.add_args([
            {
                'name': 'slurm_host',
                'msg': 'This is slurm',
                'required': False,
                'pos': False,
                'type': bool,
                'default': False
            },
            {
                'name': 'pbs_host',
                'msg': 'This is pbs',
                'required': False,
                'pos': False,
                'type': bool,
                'default': False
            }
        ])

    def define_env_opts(self):
        # jarvis env
        self.add_menu('env',
                      msg='Tools to edit jarvis environments')

        # jarvis env build
        self.add_cmd('env build',
                      msg="Create a custom environment.",
                      keep_remainder=True,
                      remainder_as_kv=True)
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to create',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis env destroy
        self.add_cmd('env destroy',
                      msg='Destroy a custom environment.')
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to destroy',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis env path
        self.add_cmd('env path',
                      msg='View the environment file\'s path')
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to show',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis env show
        self.add_cmd('env show',
                      msg='View the environment file\'s output')
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to show',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

        # jarvis env list
        self.add_cmd('env list',
                      msg='List all custom environments.')

        # jarvis pipeline env copy
        self.add_cmd('pipeline env copy',
                      msg='Copy and modify a custom environment.',
                      keep_remainder=True,
                      remainder_as_kv=True)
        self.add_args([
            {
                'name': 'env_name',
                'msg': 'The name of the environment to create',
                'required': True,
                'pos': True,
                'default': None
            },
        ])

    """
    INITIALIZATION CLI
    """

    def init(self):
        self.jarvis.create(self.kwargs['CONFIG_DIR'],
                           self.kwargs['PRIVATE_DIR'],
                           self.kwargs['SHARED_DIR'])

    def config_print(self):
        self.jarvis.print_config()

    def config_path(self):
        self.jarvis.print_config_path()

    def bootstrap_from(self):
        self.jarvis.bootstrap_from(self.kwargs['MACHINE'])

    def bootstrap_list(self):
        self.jarvis.bootstrap_list()

    def reset(self):
        while True:
            x = input('Are you sure you want to destroy all pipelines? '
                      '(yes/no): ')
            if x == 'yes':
                break
            elif x == 'no':
                print('Not removing anything.')
                return
            else:
                print(f'{x} is neither yes or no')
        self.jarvis.reset()

    """
    RESOURCE GRAPH CLI
    """

    def hostfile_set(self):
        self.jarvis.set_hostfile(self.kwargs['path'])
        self.jarvis.save()

    def resource_graph_show(self):
        self.jarvis.resource_graph_show()
        self.jarvis.save()

    def resource_graph_path(self):
        print(self.jarvis.resource_graph_path)
        self.jarvis.save()

    def resource_graph_build(self):
        self.make_hostfile_from_sched(Path.home())
        if not self.run_on_first_host(self.jarvis.hostfile):
            return
        net_sleep = self.kwargs['net_sleep']
        self.jarvis.resource_graph_build(net_sleep)
        self.jarvis.save()

    def resource_graph_build_sbatch(self):
        slurm_info = SlurmExecInfo.parse_args(self.kwargs)
        slurm_cmd = [
            f'jarvis rg build +slurm_host'
        ]
        if slurm_info.host_suffix is not None:
            slurm_cmd.append(f'host_suffix={slurm_info.host_suffix}')
        slurm_cmd = ' '.join(slurm_cmd)
        SlurmExec(slurm_cmd, slurm_info)

    def resource_graph_modify(self):
        net_sleep = self.kwargs['net_sleep']
        self.jarvis.resource_graph_modify(net_sleep)
        self.jarvis.save()

    def resource_graph_prune(self):
        self.jarvis.resource_graph.walkthrough_prune(
            PsshExecInfo(hostfile=self.jarvis.hostfile))

    def resource_graph_add_storage(self):
        self._resource_graph_hostfile()
        self.jarvis.resource_graph.add_storage(**self.kwargs)
        self.jarvis.save()

    def resource_graph_add_net(self):
        self._resource_graph_hostfile()
        self.jarvis.resource_graph.add_net(**self.kwargs)
        self.jarvis.save()

    def resource_graph_filter_fs(self):
        self.jarvis.resource_graph.filter_fs(**self.kwargs)
        self.jarvis.save()

    def resource_graph_filter_net(self):
        self._resource_graph_hostfile()
        self.jarvis.resource_graph.filter_net(**self.kwargs)
        self.jarvis.save()

    def _resource_graph_hostfile(self):
        if self.kwargs['hosts'] is not None:
            self.kwargs['hosts'] = Hostfile(text=self.kwargs['hosts'])
        elif self.kwargs['hostfile'] is not None:
            self.kwargs['hosts'] = Hostfile(hostfile=self.kwargs['hostfile'])
        else:
            self.kwargs['hosts'] = self.jarvis.hostfile
        del self.kwargs['hostfile']

    """
    REPO CLI
    """

    def repo_add(self):
        self.jarvis.add_repo(self.kwargs['repo_path'], self.kwargs['force'])
        self.jarvis.save()

    def repo_create(self):
        pkg_cls = self.kwargs['pkg_cls']
        pkg_type = self.kwargs['pkg_type']
        self.jarvis.create_pkg(pkg_cls, pkg_type)
        self.jarvis.save()

    def repo_promote(self):
        self.jarvis.promote_repo(self.kwargs['repo_name'])
        self.jarvis.save()

    def repo_remove(self):
        self.jarvis.remove_repo(self.kwargs['repo_name'])
        self.jarvis.save()

    def repo_list(self):
        if self.kwargs['repo_name'] is not None:
            self.jarvis.list_repo(self.kwargs['repo_name'])
        else:
            self.jarvis.list_repos()

    """
    ENV CLI
    """

    def env_build(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().build_static_env(kwargs['env_name'], kwargs)

    def env_path(self):
        print(Pipeline().get_static_env_path(self.kwargs['env_name']))

    def env_show(self):
        Pipeline().static_env_show(self.kwargs['env_name'])

    def env_destroy(self):
        Pipeline().destroy_static_env(self.kwargs['env_name'])

    def env_list(self):
        Pipeline().list_static_env()

    """
    PIPELINE CLI
    """

    def cd(self):
        self.jarvis.cd(self.kwargs['pipeline_id'])
        self.jarvis.save()

    def path(self):
        pipeline_id = self.kwargs['pipeline_id']
        pkg_id = self.kwargs['pkg_id']
        config = self.kwargs['config']
        shared = self.kwargs['shared']
        private = self.kwargs['private']
        pipeline = Pipeline().load(pipeline_id, with_config=False)
        if pkg_id is not None:
            path = pipeline.get_pkg(pkg_id).get_path(config, shared, private)
        else:
            path = pipeline.get_path(config, shared, private)
        print(path)

    def getcwd(self):
        print(self.jarvis.cur_pipeline)

    def pipeline_list(self):
        for pipeline_ctx in self.jarvis.list_pipelines():
            print(pipeline_ctx)

    def pipeline_create(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().create(pipeline_id).save()
        self.jarvis.cd(pipeline_id)
        self.jarvis.save()

    def pipeline_load_yaml(self):
        path = self.kwargs['path']
        pipeline = Pipeline().from_yaml(path).save()
        self.jarvis.cd(pipeline.global_id)
        self.jarvis.save()

    def pipeline_update_yaml(self):
        ppl_id = self.kwargs['pipeline_id']
        Pipeline().load(ppl_id).update_yaml().save()

    def pipeline_run_yaml(self):
        path = self.kwargs['path']
        pipeline = Pipeline().from_yaml(path).save()
        self.jarvis.cd(pipeline.global_id)
        pipeline.run()
        self.jarvis.save()
        exit(pipeline.exit_code)

    def pipeline_reset(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().load(pipeline_id, with_config=False).reset()
        self.jarvis.save()

    def pipeline_env_path(self):
        pipeline_id = self.kwargs['pipeline_id']
        pipeline = Pipeline().load(pipeline_id)
        print(pipeline.env_path)

    def pipeline_env_show(self):
        pipeline_id = self.kwargs['pipeline_id']
        pipeline = Pipeline().load(pipeline_id)
        pipeline.env_show()

    def pipeline_destroy(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().load(pipeline_id).destroy()
        self.jarvis.save()

    def pipeline_print(self):
        pipeline_id = self.kwargs['pipeline_id']
        Pipeline().load(pipeline_id).view_pkgs()

    def pipeline_env_build(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().load().build_env(kwargs).save()

    def pipeline_env_copy(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().load().copy_static_env(kwargs['env_name'], kwargs).save()

    def pipeline_env_track(self):
        kwargs = {}
        kwargs.update(self.kwargs)
        kwargs.update(self.remainder_kv)
        Pipeline().load().track_env(kwargs.keys()).save()

    def pipeline_env_scan(self):
        Pipeline().load().scan_env(self.kwargs).save()

    def maybe_configure(self, pipeline, pkg_id):
        pkg = pipeline.get_pkg(pkg_id)
        menu = pkg.configure_menu()
        args = PkgArgParse(args=self.remainder, menu=menu)
        if self.kwargs['conf']:
            pipeline.configure(pkg_id, **args.kwargs)
        else:
            pkg.update_env(pipeline.env)
            pkg.update_config(args.kwargs)
        pipeline.save()

    def pipeline_append(self):
        pkg_id = self.kwargs['pkg_id']
        pipeline = Pipeline().load()
        if pkg_id is None:
            pkg_id = self.kwargs['pkg_type']
        pipeline.append(self.kwargs['pkg_type'],
                        pkg_id=pkg_id,
                        do_configure=False)
        self.maybe_configure(pipeline, pkg_id)

    def pipeline_prepend(self):
        pkg_id = self.kwargs['pkg_id']
        pipeline = Pipeline().load()
        if pkg_id is None:
            pkg_id = self.kwargs['pkg_type']
        pipeline.prepend(self.kwargs['pkg_type'],
                         pkg_id=pkg_id,
                         do_configure=False)
        self.maybe_configure(pipeline, pkg_id)

    def pipeline_insert(self):
        at_id = self.kwargs['at_id']
        pkg_id = self.kwargs['pkg_id']
        pipeline = Pipeline().load()
        if pkg_id is None:
            pkg_id = self.kwargs['pkg_type']
        pipeline.insert(self.kwargs['at_id'],
                        self.kwargs['pkg_type'],
                        pkg_id=pkg_id,
                        do_configure=False)
        self.maybe_configure(pipeline, pkg_id)

    def pipeline_update(self):
        ppl_id = self.kwargs['pipeline_id']
        Pipeline().load(ppl_id).update().save()

    def pkg_unlink(self):
        Pipeline().load().unlink(self.kwargs['pkg_id']).save()

    def pkg_remove(self):
        Pipeline().load().remove(self.kwargs['pkg_id']).save()

    def pkg_help(self):
        pkg_type = self.kwargs['pkg_type']
        pkg = self.jarvis.construct_pkg(pkg_type)
        menu = pkg.configure_menu()
        args = PkgArgParse(args=[], menu=menu)
        args.binary_name = pkg_type
        args._print_help()

    def pkg_src(self):
        pkg_type = self.kwargs['pkg_type']
        pkg = self.jarvis.construct_pkg(pkg_type)
        print(f'{pkg.pkg_dir}/pkg.py')

    def pkg_root(self):
        pkg_type = self.kwargs['pkg_type']
        pkg = self.jarvis.construct_pkg(pkg_type)
        print(pkg.pkg_dir)

    def pkg_configure(self):
        pipeline = Pipeline().load()
        pkg = pipeline.get_pkg(self.kwargs['pkg_id'])
        menu = pkg.configure_menu()
        args = PkgArgParse(args=self.remainder, menu=menu)
        if self.kwargs['conf']:
            if args.kwargs['reinit']:
                pkg.configure(**args.kwargs)
            else:
                pkg.configure(**args.real_kwargs)
        else:
            pkg.update_env(pipeline.env)
            pkg.update_config(args.kwargs)
        pipeline.save()

    def sched_hostfile_build(self):
        self.make_hostfile_from_sched(Path.home())
        if self.run_on_first_host(self.jarvis.hostfile):
            print('1')
            self.jarvis.save()
        else:
            print('0')

    def run_on_first_host(self, hostfile):
        if self.kwargs['slurm_host'] or self.kwargs['pbs_host']:
            this_host_ip = socket.gethostbyname(socket.gethostname())
            first_host_ip = socket.gethostbyname(hostfile.hosts[0])
            if this_host_ip != first_host_ip:
                return False
        return True

    def make_hostfile_from_sched(self, conf_dir, host_suffix=None):
        file_location = os.path.join(conf_dir,
                                     'jarvis_hostfile.txt')
        if self.kwargs['slurm_host']:
            SlurmHostfile(file_location, host_suffix)
            self.jarvis.set_hostfile(file_location)
            return True
        if self.kwargs['pbs_host']:
            orig_nodefile = os.environ.get('PBS_NODEFILE')
            if self.kwargs['polaris']:
                hostfile = Hostfile(hostfile=orig_nodefile)
                for i, host in enumerate(hostfile.hosts):
                    hostfile.hosts[i] = host.split('.')[0]
            hostfile.save(file_location)
            self.jarvis.set_hostfile(file_location)
            return True
        return False

    def pipeline_run(self):
        if self.kwargs['slurm']:
            self.pipeline_sbatch()
            return
        elif self.kwargs['pbs']:
            self.pipeline_pbs()
            return
        if self.kwargs['script']:
            pipeline = Pipeline().from_yaml(self.kwargs['script'])
        else:
            pipeline_name = self.kwargs['pipeline_name']
            pipeline = Pipeline().load(pipeline_name)
        if self.make_hostfile_from_sched(pipeline.config_dir):
            pipeline.update().save()
        if not self.run_on_first_host(self.jarvis.hostfile):
            return
        if 'iterator' in pipeline.config:
            pipeline.run_iter()
        else:
            pipeline.run()
        exit(pipeline.exit_code)

    def pipeline_sbatch(self):
        pipeline_name = self.kwargs['pipeline_name']
        pipeline = Pipeline().load(pipeline_name)
        pipeline_name = pipeline.global_id
        if not self.kwargs['job_name']:
            job_name = f'{pipeline_name}_{self.kwargs["nnodes"]}'
            print(f'No name set for the job. Setting it to {job_name}')
            self.kwargs['job_name'] = job_name
        slurm_info = SlurmExecInfo.parse_args(self.kwargs)
        slurm_cmd = [
            f'jarvis pipeline run {pipeline_name} +slurm_host'
        ]
        if slurm_info.host_suffix is not None:
            slurm_cmd.append(f'host_suffix={slurm_info.host_suffix}')
        slurm_cmd = ' '.join(slurm_cmd)
        SlurmExec(slurm_cmd, slurm_info)

    def pipeline_pbs(self):
        pipeline = Pipeline().load()
        pipeline_name = pipeline.global_id
        num_nodes = self.kwargs['nnodes']
        script_location = f'{pipeline.config_dir}/{pipeline_name}_{num_nodes}.sh'
        pbs_info = PbsExecInfo.from_kwargs(self.kwargs, script_location)
        cmd = [
            f'jarvis pipeline run {pipeline_name} +pbs_host'
        ]
        if self.kwargs['polaris']:
            cmd.append('+polaris')
        cmd = ' '.join(cmd)
        PbsExec(cmd, pbs_info)

    def pipeline_start(self):
        Pipeline().load().start()

    def pipeline_stop(self):
        Pipeline().load().stop()

    def pipeline_kill(self):
        Pipeline().load().kill()

    def pipeline_clean(self):
        Pipeline().load().clean()

    def pipeline_status(self):
        Pipeline().load().status()

    def pipeline_load(self):
        Pipeline().load().status()

    def pipeline_save(self):
        Pipeline().load().status()

    """
    PIPELINE INDEX CLI
    """
    def pipeline_index_show(self):
        index_query = self.kwargs['index_query']
        PipelineIndex(index_query).show()
    
    def pipeline_index_copy(self):
        index_query = self.kwargs['index_query']
        output_dir = self.kwargs['output_dir']
        PipelineIndex(index_query).copy(output_dir)

    def pipeline_index_load(self):
        index_query = self.kwargs['index_query']
        PipelineIndex(index_query).load_script().save()


if __name__ == '__main__':
    args = JarvisArgs()
    args.process_args()

